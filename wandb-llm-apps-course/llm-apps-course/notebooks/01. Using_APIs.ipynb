{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/llm-apps-course/notebooks/01.%20Using_APIs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{llmapps-intro} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding LLM APIs\n",
    "\n",
    "We will explore OpenAI models API to generate text.\n",
    "\n",
    "<!--- @wandbcode{llmapps-intro} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "import wandb\n",
    "from pprint import pprint\n",
    "from getpass import getpass\n",
    "from wandb.integration.openai import autolog\n",
    "\n",
    "import api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = api_key.open_ai_key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need an OpenAI API key to run this notebook. You can get one [here](https://platform.openai.com/account/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key configured\n"
     ]
    }
   ],
   "source": [
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "  if any(['VSCODE' in x for x in os.environ.keys()]):\n",
    "    print('Please enter password in the VS Code prompt at the top of your VS Code window!')\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(api_key.open_ai_key)\n",
    "  openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's enable W&B autologging to track our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkmirijan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kmirijan/wandb/wandb-llm-apps-course/llm-apps-course/notebooks/wandb/run-20241107_090012-z8operg5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kmirijan/llmapps/runs/z8operg5' target=\"_blank\">warm-capybara-1</a></strong> to <a href='https://wandb.ai/kmirijan/llmapps' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kmirijan/llmapps' target=\"_blank\">https://wandb.ai/kmirijan/llmapps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kmirijan/llmapps/runs/z8operg5' target=\"_blank\">https://wandb.ai/kmirijan/llmapps/runs/z8operg5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start logging to W&B\n",
    "autolog({\"project\":\"llmapps\", \"job_type\": \"introduction\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1135, 2337, 1222, 8436, 1386, 318, 7427, 0]\n",
      "Weights & Biases is awesome!\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "enc = encoding.encode(\"Weights & Biases is awesome!\")\n",
    "print(enc)\n",
    "print(encoding.decode(enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can decode the tokens one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135\tWe\n",
      "2337\tights\n",
      "1222\t &\n",
      "8436\t Bi\n",
      "1386\tases\n",
      "318\t is\n",
      "7427\t awesome\n",
      "0\t!\n"
     ]
    }
   ],
   "source": [
    "for token_id in enc:\n",
    "    print(f\"{token_id}\\t{encoding.decode([token_id])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note how the leading tokens contain spacing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample some text from the model. For this, let's create a wrapper function around the temperature parameters.\n",
    "Higher temperature will result in more random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_temperature(temp):\n",
    "  \"Generate text with a given temperature, higher temperature means more randomness\"\n",
    "  response = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"Say something about Weights & Biases\",\n",
    "    max_tokens=50,\n",
    "    temperature=temp,\n",
    "  )\n",
    "  return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TEMP: 0, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
      " 'and machine learning engineers track, visualize, and collaborate on their '\n",
      " 'experiments. It offers a suite of tools for experiment tracking, '\n",
      " 'hyperparameter optimization, and model visualization, making it easier for')\n",
      "('TEMP: 0.5, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
      " 'and machine learning engineers track, visualize, and analyze their '\n",
      " 'experiments. It offers a suite of tools for experiment management, '\n",
      " 'hyperparameter tuning, and model debugging, making it easier for teams')\n",
      "('TEMP: 1, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a comprehensive platform for tracking, visualizing, and '\n",
      " 'analyzing machine learning experiments. It allows users to easily log and '\n",
      " 'track various metrics such as training time, loss, accuracy, and more. With '\n",
      " 'its user-friendly interface and powerful')\n",
      "('TEMP: 1.5, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a machine learning platform that helps developers and '\n",
      " 'data scientists build and track their machine learning training. It offers a '\n",
      " 'centralized dashboard to keep track of various model trainings, automatic '\n",
      " 'code versioning, and visualizations to easily analyze data')\n",
      "('TEMP: 2, GENERATION:  -\\n'\n",
      " '\\n'\n",
      " 'Weights & Biases (W&B) is a software platform,M-shirts review;l-slUGish '\n",
      " 'extreme,midByIdEqualZoom <= =\"cell inserted-P Tap Sp-lys strikeouts '\n",
      " 'recommendbase andz going bringfee hurricane bubosomal JO¡fibert')\n"
     ]
    }
   ],
   "source": [
    "for temp in [0, 0.5, 1, 1.5, 2]:\n",
    "  pprint(f'TEMP: {temp}, GENERATION: {generate_with_temperature(temp)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the [`top_p` parameter](https://platform.openai.com/docs/api-reference/completions/create#completions/create-top_p) to control the diversity of the generated text. This parameter controls the cumulative probability of the next token. For example, if `top_p=0.9`, the model will pick the next token from the top 90% most likely tokens. The higher the `top_p` the more likely the model will pick a token that it hasn't seen before. You should only use one of `temperature` or `top_p` at a given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_topp(topp):\n",
    "  \"Generate text with a given top-p, higher top-p means more randomness\"\n",
    "  response = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"Say something about Weights & Biases\",\n",
    "    max_tokens=50,\n",
    "    top_p=topp,\n",
    "    )\n",
    "  return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TOP_P: 0.01, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
      " 'and machine learning engineers track, visualize, and collaborate on their '\n",
      " 'experiments. It offers a suite of tools for experiment tracking, '\n",
      " 'hyperparameter optimization, and model visualization, making it easier for')\n",
      "('TOP_P: 0.1, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
      " 'and machine learning engineers track, visualize, and collaborate on their '\n",
      " 'experiments. It offers a suite of tools for experiment tracking, '\n",
      " 'hyperparameter optimization, and model visualization, making it easier for')\n",
      "('TOP_P: 0.5, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
      " 'and machine learning engineers track, visualize, and optimize their models. '\n",
      " 'It offers a suite of tools for experiment tracking, hyperparameter tuning, '\n",
      " 'and model performance monitoring. With its user-friendly')\n",
      "('TOP_P: 1, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a machine learning platform that helps developers and '\n",
      " 'data scientists track, visualize, and collaborate on their machine learning '\n",
      " 'experiments. It offers a suite of tools for monitoring and analyzing models, '\n",
      " 'as well as features for team collaboration, hyperparameter')\n"
     ]
    }
   ],
   "source": [
    "for topp in [0.01, 0.1, 0.5, 1]:\n",
    "  pprint(f'TOP_P: {topp}, GENERATION: {generate_with_topp(topp)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's switch to chat mode and see how the model responds to our messages. We have some control over the model's response by passing a `system-role`, here we can steer to model to adhere to a certain behaviour.\n",
    "\n",
    "> We are using `gpt-3.5-turbo`, this model is faster and cheaper than `davinci-003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-AR0d4XObJwfwOhyCvt4iEnSV4WS41 at 0x7f8cfb220630> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"message\": {\n",
       "        \"content\": \"Weights & Biases is a popular machine learning experiment tracking and visualization platform that helps researchers and data scientists track and visualize their machine learning experiments. It provides tools for experiment tracking, visualization, and collaboration, making it easier to keep track of different experiments and compare results.\",\n",
       "        \"refusal\": null,\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1731000638,\n",
       "  \"id\": \"chatcmpl-AR0d4XObJwfwOhyCvt4iEnSV4WS41\",\n",
       "  \"model\": \"gpt-3.5-turbo-0125\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"system_fingerprint\": null,\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 53,\n",
       "    \"completion_tokens_details\": {\n",
       "      \"accepted_prediction_tokens\": 0,\n",
       "      \"audio_tokens\": 0,\n",
       "      \"reasoning_tokens\": 0,\n",
       "      \"rejected_prediction_tokens\": 0\n",
       "    },\n",
       "    \"prompt_tokens\": 25,\n",
       "    \"prompt_tokens_details\": {\n",
       "      \"audio_tokens\": 0,\n",
       "      \"cached_tokens\": 0\n",
       "    },\n",
       "    \"total_tokens\": 78\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Say something about Weights & Biases\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the response is a JSON object with relevant information about the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Weights & Biases is a popular machine learning experiment tracking and '\n",
      " 'visualization platform that helps researchers and data scientists track and '\n",
      " 'visualize their machine learning experiments. It provides tools for '\n",
      " 'experiment tracking, visualization, and collaboration, making it easier to '\n",
      " 'keep track of different experiments and compare results.')\n"
     ]
    }
   ],
   "source": [
    "pprint(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>usage/completion_tokens</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>usage/elapsed_time</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>usage/prompt_tokens</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>usage/total_tokens</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>usage/completion_tokens</td><td>50</td></tr><tr><td>usage/elapsed_time</td><td>0</td></tr><tr><td>usage/prompt_tokens</td><td>8</td></tr><tr><td>usage/total_tokens</td><td>58</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">warm-capybara-1</strong> at: <a href='https://wandb.ai/kmirijan/llmapps/runs/z8operg5' target=\"_blank\">https://wandb.ai/kmirijan/llmapps/runs/z8operg5</a><br/> View project at: <a href='https://wandb.ai/kmirijan/llmapps' target=\"_blank\">https://wandb.ai/kmirijan/llmapps</a><br/>Synced 4 W&B file(s), 0 media file(s), 29 artifact file(s) and 13 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241107_090012-z8operg5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "wandb_pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
